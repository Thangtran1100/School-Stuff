{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science (CS4661). Cal State Univ. LA, CS Dept.\n",
    "### Instructor: Dr. Mohammad Porhomayoun\n",
    "---------------------------------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data Science in Python\n",
    "\n",
    "#### This is an introduction to some data sceince libraries/packages in python. Feel free to refer to the suggested resources and documentaries for more details.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Library (sklearn):\n",
    "Scikit-learn is the Python Machine Learning Library. It includes optimal implementation of various classification, regression and clustering algorithms. It also includes hundreds of commands and functions for data preprocessing and processing along with a number of default datasets to work with.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#    KNN CLASSIFIER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Main Steps to build (train) and use (test/predict) a predictive model in sklearn:\n",
    "\n",
    "## Step1: Importing the sklearn class (machine learning algorithm) that you would like to use for modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following line will import KNeighborsClassifier \"Class\"\n",
    "# KNeighborsClassifier is name of a \"sklearn class\" to perform \"KNN Classification\" \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required packages and libraries\n",
    "# we will need numpy and pandas later\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Notice: The term \"class\" here refers to class and object concepts in object oriented programming! It has nothing to do with \"classification or classifier\" !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Set up the Feature Matrix and Label Vector:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start with iris data as a popular and simple dataset:\n",
    "### There are three ways to access iris dataset:\n",
    "\n",
    "#### 1- Reading the iris dataset directly from the web.\n",
    "\n",
    "#### 2- Download the iris dataset (e.g. as a csv file) in your computer, and then open and read it.\n",
    "\n",
    "#### 3- Since iris dataset is very popular and widely used, it is already embedded in sklearn library. Thus, for now we import and use the embedded version of iris from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing iris from sklearn embedded datasets\n",
    "# The following line only import the load_iris function from sklearn library. \n",
    "# This function can generate an object containing iris dataset \n",
    "\n",
    "from sklearn.datasets import load_iris "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the sklearn function load_iris() to instantiate an \"object\" containing iris datset: \n",
    "\n",
    "iris = load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "# \"data\" attribute will return the iris dataset features:\n",
    "\n",
    "X = iris.data  # X will be feature matrix\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# \"feature_names\" attribute will return the name of features:\n",
    "\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape) # this line print the size of iris.data (iris feature matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# \"target\" attribute will return the iris dataset labels \n",
    "# for the sklearn embedded iris dataset, the labels are already converted to numeric\n",
    "\n",
    "y = iris.target  # y will be label vector\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape) # this line print the size of iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# \"target_names\" attribute will return the name of encoded labels: 0 = setosa, 1 = versicolor, 2 = virginica\n",
    "\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Important Notice: \n",
    "#### In this example, \"iris\"  will be an object of sklearn containing iris dataset and other above \"attribtes\". In general, when we read and work with an \"arbitrary dataset\", we do not have the above attributes. In this case, we can use Pandas DataFrame (as mentioned in previous tuotrial) to represent features and labels (see below for more details)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Defining (instantiating) an \"object\" from the sklearn class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following line, \"knn\" is instantiated as an \"object\" of KNeighborsClassifier \"class\". \n",
    "\n",
    "k = 1\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='uniform') \n",
    "\n",
    "# weights{‘uniform’, ‘distance’}, callable or None, default=’uniform’\n",
    "# ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "# ‘distance’ : weight points by the inverse of their distance. \n",
    "# in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that in this example the number of neighbors \"k\" is definied as 1 (n_neighbors=1) \n",
    "- Note that the name of the object (\"knn\" in this example) is just an arbitrary name. We usually use a name that makes sense.\n",
    "- Notice that we define the classifier parameters in this step (e.g. k=1). \n",
    "- To check the full list of adjustable parameters and default values, feel free to check the sklearn documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: Traning Stage: Traning a predictive model using the training dataset:\n",
    "#### Traning Stage called Fitting in sklearn\n",
    "#### Method \"fit\" is used for many sklearn classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the method \"fit\" of the \"object knn\" along with training dataset and labels to train the model.\n",
    "\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5: Testing (Prediction) Stage: Making prediction on new observations (Testing Data) using the trained model:\n",
    "##### Now, Suppose that we have a new observation (a new data sample) with Known features [6, 3, 5.9, 2.9], and Unknown label. What would be our predition for the label of this new observation?\n",
    "#### Testing Stage is called Predict in sklearn\n",
    "#### Method \"predict\" is used for many sklearn classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# We can use the method \"predict\" of the *trained* object knn on one or more testing data sample to perform prediction:\n",
    "\n",
    "X_Testing = [[6, 3, 5.9, 2.9]]\n",
    "\n",
    "y_predict = knn.predict(X_Testing)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0]\n"
     ]
    }
   ],
   "source": [
    "# We can use the method \"predict\" of the *trained* object knn on one or more testing data sample to perform prediction:\n",
    "# Two new data samples:\n",
    "\n",
    "X_Testing = [[6, 3, 5.9, 2.9],[3.2, 3, 1.9, 0.3]]\n",
    "\n",
    "y_predict = knn.predict(X_Testing)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification on arbitrary datasets from external sources (loading an arbitrary dataset from web or local database):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1-5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following line will import KNeighborsClassifier \"Class\"\n",
    "# KNeighborsClassifier is name of a \"sklearn class\" to perform \"KNN Classification\" \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required packages and libraries\n",
    "# we will need numpy and pandas later\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading a CSV file directly from Web, and store it in a pandas DataFrame:\n",
    "# \"read_csv\" is a pandas function to read csv files from web or local device:\n",
    "\n",
    "iris_df = pd.read_csv('https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "0             5.1          3.5           1.4          0.2      setosa\n",
       "10            5.4          3.7           1.5          0.2      setosa\n",
       "20            5.4          3.4           1.7          0.2      setosa\n",
       "30            4.8          3.1           1.6          0.2      setosa\n",
       "40            5.0          3.5           1.3          0.3      setosa\n",
       "50            7.0          3.2           4.7          1.4  versicolor\n",
       "60            5.0          2.0           3.5          1.0  versicolor\n",
       "70            5.9          3.2           4.8          1.8  versicolor\n",
       "80            5.5          2.4           3.8          1.1  versicolor\n",
       "90            5.5          2.6           4.4          1.2  versicolor\n",
       "100           6.3          3.3           6.0          2.5   virginica\n",
       "110           6.5          3.2           5.1          2.0   virginica\n",
       "120           6.9          3.2           5.7          2.3   virginica\n",
       "130           7.4          2.8           6.1          1.9   virginica\n",
       "140           6.7          3.1           5.6          2.4   virginica"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the dataset by printing every 10 lines:\n",
    "iris_df[0::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "0             5.1          3.5           1.4          0.2      setosa\n",
       "10            5.4          3.7           1.5          0.2      setosa\n",
       "20            5.4          3.4           1.7          0.2      setosa\n",
       "30            4.8          3.1           1.6          0.2      setosa\n",
       "40            5.0          3.5           1.3          0.3      setosa\n",
       "50            7.0          3.2           4.7          1.4  versicolor\n",
       "60            5.0          2.0           3.5          1.0  versicolor\n",
       "70            5.9          3.2           4.8          1.8  versicolor\n",
       "80            5.5          2.4           3.8          1.1  versicolor\n",
       "90            5.5          2.6           4.4          1.2  versicolor\n",
       "100           6.3          3.3           6.0          2.5   virginica\n",
       "110           6.5          3.2           5.1          2.0   virginica\n",
       "120           6.9          3.2           5.7          2.3   virginica\n",
       "130           7.4          2.8           6.1          1.9   virginica\n",
       "140           6.7          3.1           5.6          2.4   virginica"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the dataset by printing every 10 lines:\n",
    "\n",
    "iris_df[0::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Feature Matrix for iris dataset:\n",
    "\n",
    "# create a python list of feature names that would like to pick from the dataset:\n",
    "feature_cols = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "\n",
    "# use the above list to select the features from the original DataFrame\n",
    "X = iris_df[feature_cols]  \n",
    "\n",
    "# print the first 5 rows\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "# checking the size of Feature Matix X:\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          setosa\n",
       "10         setosa\n",
       "20         setosa\n",
       "30         setosa\n",
       "40         setosa\n",
       "50     versicolor\n",
       "60     versicolor\n",
       "70     versicolor\n",
       "80     versicolor\n",
       "90     versicolor\n",
       "100     virginica\n",
       "110     virginica\n",
       "120     virginica\n",
       "130     virginica\n",
       "140     virginica\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a Series of labels (the last column) from the DataFrame\n",
    "# y = iris_df['label'] # this is the index that we gave to the labels\n",
    "# OR:\n",
    "y = iris_df['species'] # this is the original categorical labels (the latest revision of sklearn accepts non-numerical labels)\n",
    "\n",
    "# checking the label vector by printing every 10 values\n",
    "y[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating another \"object\" of KNeighborsClassifier \"class\" with k=3:\n",
    "\n",
    "k = 3\n",
    "my_knn_for_cs4661 = KNeighborsClassifier(n_neighbors=k, weights='uniform') # name of the object is arbitrary!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the method \"fit\" of the object along with training dataset and labels to train the model.\n",
    "\n",
    "my_knn_for_cs4661.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['virginica' 'setosa']\n"
     ]
    }
   ],
   "source": [
    "# We use the method \"predict\" of the *trained* object knn on one or more testing data sample to perform prediction:\n",
    "\n",
    "# Prediction for Two new data samples:\n",
    "\n",
    "X_Testing = [[6, 3, 5.9, 2.9],[3.2, 3, 1.9, 0.3]]\n",
    "\n",
    "y_predict = my_knn_for_cs4661.predict(X_Testing)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluating the accuracy of our classifier:\n",
    "\n",
    "#### 1- Let's split the iris dataset RANDOMLY into two new datasets: Training Set (e.g. 70% of the dataset) and Testing Set (30% of the dataset).\n",
    "#### 2- Let's pretend that we do NOT know the label of the Testing Set!\n",
    "#### 3- Let's Train the model on only Training Set, and then Predict on the Testing Set!\n",
    "#### 4- After prediction, we can compare the \"predicted labels\" for the Testing Set with its \"actual labels\" to evaluate the accuracy of our KNN Classifier!\n",
    "\n",
    "#### We will learn more about model and accuracy evaluation in future tutorials!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly splitting the original dataset into training set and testing set\n",
    "# The function\"train_test_split\" from \"sklearn.cross_validation\" library performs random splitting.\n",
    "# \"test_size=0.3\" means that pick 30% of data samples for testing set, and the rest (70%) for training set.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # We can fix the random_state for reproducibility!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4)\n",
      "(105,)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the traning set:\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 4)\n",
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the testing set:\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width\n",
      "14            5.8          4.0           1.2          0.2\n",
      "98            5.1          2.5           3.0          1.1\n",
      "75            6.6          3.0           4.4          1.4\n",
      "16            5.4          3.9           1.3          0.4\n",
      "131           7.9          3.8           6.4          2.0\n",
      "56            6.3          3.3           4.7          1.6\n",
      "141           6.9          3.1           5.1          2.3\n",
      "44            5.1          3.8           1.9          0.4\n",
      "29            4.7          3.2           1.6          0.2\n",
      "120           6.9          3.2           5.7          2.3\n",
      "94            5.6          2.7           4.2          1.3\n",
      "5             5.4          3.9           1.7          0.4\n",
      "102           7.1          3.0           5.9          2.1\n",
      "51            6.4          3.2           4.5          1.5\n",
      "78            6.0          2.9           4.5          1.5\n",
      "42            4.4          3.2           1.3          0.2\n",
      "92            5.8          2.6           4.0          1.2\n",
      "66            5.6          3.0           4.5          1.5\n",
      "31            5.4          3.4           1.5          0.4\n",
      "35            5.0          3.2           1.2          0.2\n",
      "90            5.5          2.6           4.4          1.2\n",
      "84            5.4          3.0           4.5          1.5\n",
      "77            6.7          3.0           5.0          1.7\n",
      "40            5.0          3.5           1.3          0.3\n",
      "125           7.2          3.2           6.0          1.8\n",
      "99            5.7          2.8           4.1          1.3\n",
      "33            5.5          4.2           1.4          0.2\n",
      "19            5.1          3.8           1.5          0.3\n",
      "73            6.1          2.8           4.7          1.2\n",
      "146           6.3          2.5           5.0          1.9\n",
      "91            6.1          3.0           4.6          1.4\n",
      "135           7.7          3.0           6.1          2.3\n",
      "69            5.6          2.5           3.9          1.1\n",
      "128           6.4          2.8           5.6          2.1\n",
      "114           5.8          2.8           5.1          2.4\n",
      "48            5.3          3.7           1.5          0.2\n",
      "53            5.5          2.3           4.0          1.3\n",
      "28            5.2          3.4           1.4          0.2\n",
      "54            6.5          2.8           4.6          1.5\n",
      "108           6.7          2.5           5.8          1.8\n",
      "112           6.8          3.0           5.5          2.1\n",
      "17            5.1          3.5           1.4          0.3\n",
      "119           6.0          2.2           5.0          1.5\n",
      "103           6.3          2.9           5.6          1.8\n",
      "58            6.6          2.9           4.6          1.3\n",
      "\n",
      "\n",
      "14         setosa\n",
      "98     versicolor\n",
      "75     versicolor\n",
      "16         setosa\n",
      "131     virginica\n",
      "56     versicolor\n",
      "141     virginica\n",
      "44         setosa\n",
      "29         setosa\n",
      "120     virginica\n",
      "94     versicolor\n",
      "5          setosa\n",
      "102     virginica\n",
      "51     versicolor\n",
      "78     versicolor\n",
      "42         setosa\n",
      "92     versicolor\n",
      "66     versicolor\n",
      "31         setosa\n",
      "35         setosa\n",
      "90     versicolor\n",
      "84     versicolor\n",
      "77     versicolor\n",
      "40         setosa\n",
      "125     virginica\n",
      "99     versicolor\n",
      "33         setosa\n",
      "19         setosa\n",
      "73     versicolor\n",
      "146     virginica\n",
      "91     versicolor\n",
      "135     virginica\n",
      "69     versicolor\n",
      "128     virginica\n",
      "114     virginica\n",
      "48         setosa\n",
      "53     versicolor\n",
      "28         setosa\n",
      "54     versicolor\n",
      "108     virginica\n",
      "112     virginica\n",
      "17         setosa\n",
      "119     virginica\n",
      "103     virginica\n",
      "58     versicolor\n",
      "Name: species, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "print('\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ONLY on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training ONLY on the training set:\n",
    "\n",
    "my_knn_for_cs4661.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'versicolor' 'setosa' 'virginica' 'versicolor'\n",
      " 'virginica' 'setosa' 'setosa' 'virginica' 'versicolor' 'setosa'\n",
      " 'virginica' 'versicolor' 'versicolor' 'setosa' 'versicolor' 'versicolor'\n",
      " 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'setosa'\n",
      " 'virginica' 'versicolor' 'setosa' 'setosa' 'versicolor' 'virginica'\n",
      " 'versicolor' 'virginica' 'versicolor' 'virginica' 'virginica' 'setosa'\n",
      " 'versicolor' 'setosa' 'versicolor' 'virginica' 'virginica' 'setosa'\n",
      " 'versicolor' 'virginica' 'versicolor']\n"
     ]
    }
   ],
   "source": [
    "# Testing on the testing set:\n",
    "\n",
    "y_predict = my_knn_for_cs4661.predict(X_test)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Evaluation:\n",
    "#### After prediction, we can now compare the \"predicted labels\" for the Testing Set with its \"actual labels\" to evaluate the accuracy of our KNN Classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Function \"accuracy_score\" from \"sklearn.metrics\" will perform element-to-element comparision and returns the \n",
    "# percent of correct predictions:\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example:\n",
    "y_pred    = [0, 2, 1, 1]\n",
    "y_actual  = [0, 1, 2, 1]\n",
    "\n",
    "score = accuracy_score(y_actual, y_pred)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# We can now compare the \"predicted labels\" for the Testing Set with its \"actual labels\" to evaluate the accuracy \n",
    "# Function \"accuracy_score\" from \"sklearn.metrics\" will perform the element-to-element comparision and returns the \n",
    "# portion of correct predictions:\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         actual  prediction\n",
      "14       setosa      setosa\n",
      "98   versicolor  versicolor\n",
      "75   versicolor  versicolor\n",
      "16       setosa      setosa\n",
      "131   virginica   virginica\n",
      "56   versicolor  versicolor\n",
      "141   virginica   virginica\n",
      "44       setosa      setosa\n",
      "29       setosa      setosa\n",
      "120   virginica   virginica\n",
      "94   versicolor  versicolor\n",
      "5        setosa      setosa\n",
      "102   virginica   virginica\n",
      "51   versicolor  versicolor\n",
      "78   versicolor  versicolor\n",
      "42       setosa      setosa\n",
      "92   versicolor  versicolor\n",
      "66   versicolor  versicolor\n",
      "31       setosa      setosa\n",
      "35       setosa      setosa\n",
      "90   versicolor  versicolor\n",
      "84   versicolor  versicolor\n",
      "77   versicolor  versicolor\n",
      "40       setosa      setosa\n",
      "125   virginica   virginica\n",
      "99   versicolor  versicolor\n",
      "33       setosa      setosa\n",
      "19       setosa      setosa\n",
      "73   versicolor  versicolor\n",
      "146   virginica   virginica\n",
      "91   versicolor  versicolor\n",
      "135   virginica   virginica\n",
      "69   versicolor  versicolor\n",
      "128   virginica   virginica\n",
      "114   virginica   virginica\n",
      "48       setosa      setosa\n",
      "53   versicolor  versicolor\n",
      "28       setosa      setosa\n",
      "54   versicolor  versicolor\n",
      "108   virginica   virginica\n",
      "112   virginica   virginica\n",
      "17       setosa      setosa\n",
      "119   virginica  versicolor\n",
      "103   virginica   virginica\n",
      "58   versicolor  versicolor\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "results['actual'] = y_test \n",
    "results['prediction'] = y_predict \n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about using only two feature rather than all 4 for classification?\n",
    "# Try this:\n",
    "# feature_cols = ['sepal_length','sepal_width']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Calssifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following line will import DecisionTreeClassifier \"Class\"\n",
    "# DecisionTreeClassifier is name of a \"sklearn class\" to perform \"Decision Tree Classification\" \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"my_decisiontree\" is instantiated as an \"object\" of DecisionTreeClassifier \"class\". \n",
    "\n",
    "my_decisiontree = DecisionTreeClassifier(criterion='entropy', max_depth=None,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the method \"fit\" of the objects \"my_decisiontree\" along with training dataset and labels to train the model.\n",
    "\n",
    "my_decisiontree.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(133.92000000000002, 195.696, 'X[3] <= 0.8\\nentropy = 1.582\\nsamples = 105\\nvalue = [36, 32, 37]'),\n",
       " Text(100.44000000000001, 152.208, 'entropy = 0.0\\nsamples = 36\\nvalue = [36, 0, 0]'),\n",
       " Text(167.40000000000003, 152.208, 'X[3] <= 1.65\\nentropy = 0.996\\nsamples = 69\\nvalue = [0, 32, 37]'),\n",
       " Text(66.96000000000001, 108.72, 'X[2] <= 5.0\\nentropy = 0.431\\nsamples = 34\\nvalue = [0, 31, 3]'),\n",
       " Text(33.480000000000004, 65.232, 'entropy = 0.0\\nsamples = 30\\nvalue = [0, 30, 0]'),\n",
       " Text(100.44000000000001, 65.232, 'X[0] <= 6.05\\nentropy = 0.811\\nsamples = 4\\nvalue = [0, 1, 3]'),\n",
       " Text(66.96000000000001, 21.744, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(133.92000000000002, 21.744, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(267.84000000000003, 108.72, 'X[2] <= 4.85\\nentropy = 0.187\\nsamples = 35\\nvalue = [0, 1, 34]'),\n",
       " Text(234.36, 65.232, 'X[1] <= 3.1\\nentropy = 0.811\\nsamples = 4\\nvalue = [0, 1, 3]'),\n",
       " Text(200.88000000000002, 21.744, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(267.84000000000003, 21.744, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(301.32000000000005, 65.232, 'entropy = 0.0\\nsamples = 31\\nvalue = [0, 0, 31]')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tree Structure:\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "tree.plot_tree(my_decisiontree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'versicolor' 'setosa' 'virginica' 'versicolor'\n",
      " 'virginica' 'setosa' 'setosa' 'virginica' 'versicolor' 'setosa'\n",
      " 'virginica' 'versicolor' 'versicolor' 'setosa' 'versicolor' 'versicolor'\n",
      " 'setosa' 'setosa' 'versicolor' 'versicolor' 'virginica' 'setosa'\n",
      " 'virginica' 'versicolor' 'setosa' 'setosa' 'versicolor' 'virginica'\n",
      " 'versicolor' 'virginica' 'versicolor' 'virginica' 'virginica' 'setosa'\n",
      " 'versicolor' 'setosa' 'versicolor' 'virginica' 'virginica' 'setosa'\n",
      " 'versicolor' 'virginica' 'versicolor']\n"
     ]
    }
   ],
   "source": [
    "# Testing on the testing set:\n",
    "\n",
    "y_predict = my_decisiontree.predict(X_test)\n",
    "\n",
    "print(y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# We can now compare the \"predicted labels\" for the Testing Set with its \"actual labels\" to evaluate the accuracy \n",
    "# Function \"accuracy_score\" from \"sklearn.metrics\" will perform the element-to-element comparision and returns the \n",
    "# portion of correct predictions:\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
